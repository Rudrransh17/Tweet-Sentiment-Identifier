{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31c26656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rudrransh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Rudrransh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Rudrransh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52fa4fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the original CSV file\n",
    "df = pd.read_csv('Tweet_Data\\original_tweet_data.csv', encoding='latin-1', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d67fa53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          0           1                             2         3   \n",
       "0        0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  \\\n",
       "1        0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2        0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3        0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4        0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...     ..         ...                           ...       ...   \n",
       "1599995  4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996  4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997  4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998  4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999  4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                       4                                                  5  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19e9086e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([0, 1, 2, 3, 4, 5], dtype='int64')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f72f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform preprocessing steps\n",
    "stopwords = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4147065a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove '@user' tags\n",
    "    text = re.sub(r'@[^\\s]+', '', text)\n",
    "\n",
    "    # Remove hyperlinks\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "\n",
    "    # Punctuation removal\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Stopword removal and stemming\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token for token in tokens if token not in stopwords]\n",
    "    tokens = [stemmer.stem(token) for token in tokens] \n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccc868d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to 'text' column\n",
    "df[6] = df[5].apply(preprocess_text)\n",
    "\n",
    "# Save the tokens and 'target' column to a new CSV file\n",
    "df[[0,6]].to_csv('Tweet_Data\\\\tokens_vs_target.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f741e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d7b9f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Tweet_Data\\\\tokens_vs_target.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44d15095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          0                                                  1\n",
       "0        0                                                  6\n",
       "1        0  ['awww', 'that', 'bummer', 'shoulda', 'got', '...\n",
       "2        0  ['upset', 'cant', 'updat', 'facebook', 'text',...\n",
       "3        0  ['dive', 'mani', 'time', 'ball', 'manag', 'sav...\n",
       "4        0  ['whole', 'bodi', 'feel', 'itchi', 'like', 'fi...\n",
       "...     ..                                                ...\n",
       "1599996  4         ['woke', 'school', 'best', 'feel', 'ever']\n",
       "1599997  4  ['thewdbcom', 'cool', 'hear', 'old', 'walt', '...\n",
       "1599998  4       ['readi', 'mojo', 'makeov', 'ask', 'detail']\n",
       "1599999  4  ['happi', '38th', 'birthday', 'boo', 'alll', '...\n",
       "1600000  4                        ['happi', 'charitytuesday']\n",
       "\n",
       "[1600001 rows x 2 columns]>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "200cb55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Retrieve column 1 and convert it to a list of token lists\n",
    "token_lists = df[1]\n",
    "\n",
    "# Perform TF-IDF encoding and create vectors of size 50\n",
    "vectorizer = TfidfVectorizer(max_features=50)\n",
    "tfidf_vectors = vectorizer.fit_transform(token_lists).toarray()\n",
    "\n",
    "# Create a new DataFrame with the vectors and column 0\n",
    "new_df = pd.DataFrame(tfidf_vectors)\n",
    "new_df.insert(0, \"target\", df[0])\n",
    "\n",
    "# Save the new DataFrame to a new CSV file\n",
    "new_df.to_csv('Tweet_Data\\\\vectors_vs_tokens.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "928e6858",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "del new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6badd395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          target    0    1         2    3         4    5         6    7   \n",
       "0             0  0.0  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  \\\n",
       "1             0  0.0  0.0  0.000000  0.0  0.507065  0.0  0.000000  0.0   \n",
       "2             0  0.0  0.0  0.711688  0.0  0.000000  0.0  0.000000  0.0   \n",
       "3             0  0.0  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0   \n",
       "4             0  0.0  0.0  0.000000  0.0  0.000000  0.0  0.746112  0.0   \n",
       "...         ...  ...  ...       ...  ...       ...  ...       ...  ...   \n",
       "1599996       4  0.0  0.0  0.000000  0.0  0.000000  0.0  1.000000  0.0   \n",
       "1599997       4  0.0  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0   \n",
       "1599998       4  0.0  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0   \n",
       "1599999       4  0.0  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0   \n",
       "1600000       4  0.0  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0   \n",
       "\n",
       "                8  ...        40        41   42   43   44   45   46   47   48   \n",
       "0        0.000000  ...  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \\\n",
       "1        0.000000  ...  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2        0.000000  ...  0.000000  0.702496  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3        0.637895  ...  0.770124  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4        0.000000  ...  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...           ...  ...       ...       ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1599996  0.000000  ...  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1599997  0.000000  ...  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1599998  0.000000  ...  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1599999  0.000000  ...  1.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1600000  0.000000  ...  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "          49  \n",
       "0        0.0  \n",
       "1        0.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        0.0  \n",
       "...      ...  \n",
       "1599996  0.0  \n",
       "1599997  0.0  \n",
       "1599998  0.0  \n",
       "1599999  0.0  \n",
       "1600000  0.0  \n",
       "\n",
       "[1600001 rows x 51 columns]>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Tweet_Data\\\\vectors_vs_tokens.csv')\n",
    "\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d54ea857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11',\n",
       "       '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23',\n",
       "       '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35',\n",
       "       '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47',\n",
       "       '48', '49'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fa942e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'target' column as y_data\n",
    "y_data = df['target'].values\n",
    "\n",
    "# Extract the remaining 50 columns as x_data\n",
    "x_data = df.drop('target', axis=1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4e853dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 4, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "333934cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600001,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c302e346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600001, 50)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "67b62ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.71168768, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b771df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7329681e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280000, 50)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7f4795c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280000,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "764f1a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "72bdeeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256, activation='relu',input_shape = [50]))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(5, activation = 'softmax'))  \n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0b859a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1280/1280 [==============================] - 13s 9ms/step - loss: 0.6407 - accuracy: 0.6185\n",
      "Epoch 2/10\n",
      "1280/1280 [==============================] - 12s 9ms/step - loss: 0.6259 - accuracy: 0.6279\n",
      "Epoch 3/10\n",
      "1280/1280 [==============================] - 11s 9ms/step - loss: 0.6247 - accuracy: 0.6285\n",
      "Epoch 4/10\n",
      "1280/1280 [==============================] - 11s 9ms/step - loss: 0.6241 - accuracy: 0.6294\n",
      "Epoch 5/10\n",
      "1280/1280 [==============================] - 11s 9ms/step - loss: 0.6233 - accuracy: 0.6304\n",
      "Epoch 6/10\n",
      "1280/1280 [==============================] - 11s 9ms/step - loss: 0.6228 - accuracy: 0.6309\n",
      "Epoch 7/10\n",
      "1280/1280 [==============================] - 11s 9ms/step - loss: 0.6224 - accuracy: 0.6320\n",
      "Epoch 8/10\n",
      "1280/1280 [==============================] - 13s 10ms/step - loss: 0.6221 - accuracy: 0.6319\n",
      "Epoch 9/10\n",
      "1280/1280 [==============================] - 13s 10ms/step - loss: 0.6217 - accuracy: 0.6325\n",
      "Epoch 10/10\n",
      "1280/1280 [==============================] - 12s 9ms/step - loss: 0.6215 - accuracy: 0.6328\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=1000, epochs=10)\n",
    "\n",
    "model.save('trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "088c9862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10001/10001 [==============================] - 11s 1ms/step - loss: 0.6216 - accuracy: 0.6339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6216016411781311, 0.633948028087616]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model('trained_model.h5')\n",
    "\n",
    "model.evaluate(x_val,y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
